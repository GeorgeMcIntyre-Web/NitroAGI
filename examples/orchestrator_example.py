"""
Example: How NitroAGI NEXUS Orchestrator Works in Practice

This example demonstrates the complete flow of a multi-modal AI request
through the NEXUS orchestrator with prefrontal cortex executive control.
"""

import asyncio
from typing import Dict, Any, List
from datetime import datetime

# Import NitroAGI components
from nitroagi.core.orchestrator import Orchestrator, TaskRequest, ExecutionStrategy
from nitroagi.core.base import ModuleCapability, ModuleRegistry, ProcessingContext
from nitroagi.core.message_bus import MessageBus
from nitroagi.core.memory import MemoryManager
from nitroagi.modules.language.language_module import LanguageModule
from nitroagi.modules.vision.vision_module import VisionModule
from nitroagi.modules.audio.audio_module import AudioModule


class NitroAGIDemo:
    """Demonstration of NitroAGI orchestrator in action."""
    
    def __init__(self):
        """Initialize the NitroAGI system."""
        # Create core components
        self.message_bus = MessageBus()
        self.registry = ModuleRegistry()
        self.memory = MemoryManager()
        
        # Create orchestrator with prefrontal cortex
        self.orchestrator = Orchestrator(
            registry=self.registry,
            message_bus=self.message_bus,
            max_concurrent_tasks=5
        )
        
        # Initialize modules
        self.language_module = LanguageModule({"name": "language"})
        self.vision_module = VisionModule({"name": "vision"})
        self.audio_module = AudioModule({"name": "audio"})
    
    async def setup(self):
        """Set up the system and register modules."""
        print("ğŸš€ Starting NitroAGI NEXUS System...")
        
        # Start core services
        await self.message_bus.start()
        await self.memory.initialize()
        await self.orchestrator.start()
        
        # Register modules with their capabilities
        await self.registry.register_module(
            self.language_module,
            capabilities=[
                ModuleCapability.TEXT_GENERATION,
                ModuleCapability.TEXT_UNDERSTANDING,
                ModuleCapability.TRANSLATION
            ]
        )
        
        await self.registry.register_module(
            self.vision_module,
            capabilities=[
                ModuleCapability.IMAGE_UNDERSTANDING,
                ModuleCapability.OBJECT_DETECTION
            ]
        )
        
        await self.registry.register_module(
            self.audio_module,
            capabilities=[
                ModuleCapability.SPEECH_TO_TEXT,
                ModuleCapability.AUDIO_PROCESSING
            ]
        )
        
        print("âœ… System initialized with modules: language, vision, audio")
        print("ğŸ§  Prefrontal cortex executive control activated")
    
    async def example_1_simple_text(self):
        """Example 1: Simple text generation request."""
        print("\n" + "="*60)
        print("EXAMPLE 1: Simple Text Generation")
        print("="*60)
        
        # Create request
        request = TaskRequest(
            input_data="Write a haiku about artificial intelligence",
            required_capabilities=[ModuleCapability.TEXT_GENERATION],
            execution_strategy=ExecutionStrategy.SEQUENTIAL
        )
        
        print(f"ğŸ“ Request: {request.input_data}")
        print("ğŸ§  Prefrontal Cortex Analysis:")
        
        # This happens internally in the orchestrator:
        # 1. Prefrontal cortex analyzes the request
        print("  â€¢ Task complexity: Low (single step)")
        print("  â€¢ Selected module: language")
        print("  â€¢ Predicted time: 2000ms")
        
        # Submit to orchestrator
        task_id = await self.orchestrator.submit_task(request)
        print(f"ğŸ“‹ Task ID: {task_id}")
        
        # Wait for completion
        result = await self.orchestrator.wait_for_task(task_id, timeout=10)
        
        print(f"âœ… Status: {result.status}")
        print(f"â±ï¸  Execution time: {result.execution_time_ms:.0f}ms")
        print(f"ğŸ“„ Output: {result.final_output}")
    
    async def example_2_multi_modal(self):
        """Example 2: Complex multi-modal processing."""
        print("\n" + "="*60)
        print("EXAMPLE 2: Multi-Modal Image Analysis")
        print("="*60)
        
        # Create complex request
        request = TaskRequest(
            input_data={
                "image_path": "/path/to/image.jpg",
                "goal": "Analyze this image and create a detailed marketing description"
            },
            required_capabilities=[
                ModuleCapability.IMAGE_UNDERSTANDING,
                ModuleCapability.OBJECT_DETECTION,
                ModuleCapability.TEXT_GENERATION
            ],
            execution_strategy=ExecutionStrategy.PIPELINE
        )
        
        print(f"ğŸ“ Request: {request.input_data['goal']}")
        print("ğŸ§  Prefrontal Cortex Analysis:")
        print("  â€¢ Task complexity: High (multiple steps)")
        print("  â€¢ Task decomposition:")
        print("    1. Extract visual features from image")
        print("    2. Detect and identify objects")
        print("    3. Analyze scene composition")
        print("    4. Generate marketing description")
        
        print("\nğŸ“Š Execution Plan:")
        print("  Step 1: vision module â†’ Extract features")
        print("  Step 2: vision module â†’ Object detection")
        print("  Step 3: vision module â†’ Scene analysis")
        print("  Step 4: language module â†’ Generate description")
        
        # Submit to orchestrator
        task_id = await self.orchestrator.submit_task(request)
        
        # Simulate execution monitoring
        print("\nğŸ”„ Execution Progress:")
        for i in range(4):
            await asyncio.sleep(0.5)
            print(f"  âœ“ Step {i+1} completed")
        
        result = await self.orchestrator.wait_for_task(task_id, timeout=30)
        
        print(f"\nâœ… Status: {result.status}")
        print(f"â±ï¸  Total execution time: {result.execution_time_ms:.0f}ms")
        print(f"ğŸ“„ Marketing Description: {result.final_output}")
    
    async def example_3_parallel_consensus(self):
        """Example 3: Parallel execution with consensus."""
        print("\n" + "="*60)
        print("EXAMPLE 3: Parallel Processing with Consensus")
        print("="*60)
        
        request = TaskRequest(
            input_data="Translate 'Hello World' to Spanish",
            required_capabilities=[ModuleCapability.TRANSLATION],
            execution_strategy=ExecutionStrategy.CONSENSUS  # Use multiple modules
        )
        
        print(f"ğŸ“ Request: {request.input_data}")
        print("ğŸ§  Prefrontal Cortex Analysis:")
        print("  â€¢ Strategy: Consensus (use multiple sources)")
        print("  â€¢ Parallel execution planned")
        
        print("\nğŸ”€ Parallel Execution:")
        print("  â†’ Module 1: Primary translation")
        print("  â†’ Module 2: Secondary translation")
        print("  â†’ Module 3: Verification translation")
        
        task_id = await self.orchestrator.submit_task(request)
        
        # Simulate parallel processing
        print("\nâš¡ Processing in parallel...")
        await asyncio.sleep(1)
        
        result = await self.orchestrator.wait_for_task(task_id, timeout=10)
        
        print("\nğŸ¤ Consensus Results:")
        print("  â€¢ Module 1: 'Hola Mundo'")
        print("  â€¢ Module 2: 'Hola Mundo'")
        print("  â€¢ Module 3: 'Hola Mundo'")
        print(f"âœ… Final consensus: {result.final_output}")
    
    async def example_4_error_handling(self):
        """Example 4: Error handling and intervention."""
        print("\n" + "="*60)
        print("EXAMPLE 4: Error Handling & Recovery")
        print("="*60)
        
        request = TaskRequest(
            input_data="Process this corrupted data: [INVALID]",
            required_capabilities=[ModuleCapability.TEXT_UNDERSTANDING],
            execution_strategy=ExecutionStrategy.SEQUENTIAL
        )
        
        print(f"ğŸ“ Request: {request.input_data}")
        print("ğŸ§  Prefrontal Cortex Monitoring:")
        
        task_id = await self.orchestrator.submit_task(request)
        
        print("\nâš ï¸  Error Detection:")
        print("  â€¢ Module execution failed")
        print("  â€¢ Executive Monitor triggered intervention")
        print("\nğŸ”§ Recovery Actions:")
        print("  1. Attempting retry with fallback module...")
        print("  2. Using alternative processing strategy...")
        print("  3. Applying error correction...")
        
        await asyncio.sleep(2)
        
        result = await self.orchestrator.wait_for_task(task_id, timeout=10)
        
        if result.status == "completed":
            print("\nâœ… Recovery successful!")
            print(f"ğŸ“„ Recovered output: {result.final_output}")
        else:
            print("\nâŒ Recovery failed - returning error")
            print(f"ğŸ“„ Errors: {result.errors}")
    
    async def show_communication_flow(self):
        """Demonstrate the communication flow between components."""
        print("\n" + "="*60)
        print("COMMUNICATION FLOW VISUALIZATION")
        print("="*60)
        
        print("""
        User Request
             â”‚
             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Orchestratorâ”‚
        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Prefrontal â”‚â”€â”€â”€â”€â–¶â”‚ Task         â”‚
        â”‚  Cortex     â”‚     â”‚ Decompositionâ”‚
        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Message    â”‚â”€â”€â”€â”€â–¶â”‚ Module       â”‚
        â”‚  Bus        â”‚     â”‚ Registry     â”‚
        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
        â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼            â–¼          â–¼
    Language     Vision      Audio
    Module       Module      Module
        â”‚            â”‚          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
               Redis Memory
        """)
        
        print("\nğŸ“¡ Message Flow Example:")
        print("1. User â†’ Orchestrator: 'Analyze and summarize'")
        print("2. Orchestrator â†’ Prefrontal Cortex: Plan execution")
        print("3. Prefrontal â†’ Task Decomposer: Break into subtasks")
        print("4. Orchestrator â†’ Message Bus: Publish task")
        print("5. Message Bus â†’ Vision Module: Process image")
        print("6. Vision â†’ Memory: Store analysis")
        print("7. Memory â†’ Language Module: Retrieve context")
        print("8. Language â†’ Orchestrator: Return summary")
        print("9. Orchestrator â†’ User: Final result")
    
    async def show_metrics(self):
        """Display system metrics."""
        print("\n" + "="*60)
        print("SYSTEM METRICS")
        print("="*60)
        
        metrics = self.orchestrator.get_metrics()
        pfc_state = metrics.get("prefrontal_cortex_state", {})
        
        print("\nğŸ“Š Orchestrator Metrics:")
        print(f"  â€¢ Tasks received: {metrics['tasks_received']}")
        print(f"  â€¢ Tasks completed: {metrics['tasks_completed']}")
        print(f"  â€¢ Tasks failed: {metrics['tasks_failed']}")
        print(f"  â€¢ Average execution time: {metrics['average_execution_time_ms']:.0f}ms")
        print(f"  â€¢ Active tasks: {metrics['active_tasks']}")
        print(f"  â€¢ Queue size: {metrics.get('queue_size', 0)}")
        
        print("\nğŸ§  Prefrontal Cortex State:")
        print(f"  â€¢ Current goal: {pfc_state.get('current_goal', 'None')}")
        print(f"  â€¢ Working memory items: {pfc_state.get('working_memory_items', 0)}/7")
        print(f"  â€¢ Planning stack depth: {pfc_state.get('planning_stack_depth', 0)}")
        print(f"  â€¢ Recent executions: {pfc_state.get('recent_executions', 0)}")
    
    async def run_demo(self):
        """Run the complete demonstration."""
        try:
            # Setup system
            await self.setup()
            
            # Show communication flow
            await self.show_communication_flow()
            
            # Run examples
            await self.example_1_simple_text()
            await self.example_2_multi_modal()
            await self.example_3_parallel_consensus()
            await self.example_4_error_handling()
            
            # Show metrics
            await self.show_metrics()
            
            print("\n" + "="*60)
            print("ğŸ‰ DEMONSTRATION COMPLETE")
            print("="*60)
            
        finally:
            # Cleanup
            await self.orchestrator.stop()
            print("\nğŸ‘‹ System shutdown complete")


async def main():
    """Main entry point."""
    demo = NitroAGIDemo()
    await demo.run_demo()


if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                           â•‘
    â•‘            NitroAGI NEXUS Orchestrator Demo               â•‘
    â•‘                                                           â•‘
    â•‘    Demonstrating Executive Control & Communication        â•‘
    â•‘                                                           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    asyncio.run(main())